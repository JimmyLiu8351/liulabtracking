{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/JimmyLiu8351/liulabtracking/blob/main/eye_test_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wzLp7ssS88CL",
    "outputId": "2a398dd0-43d7-4e76-d82e-5c6defdcea05"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import cProfile\n",
    "import pstats\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, Process, Queue, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9X5jjkTrOGX5"
   },
   "outputs": [],
   "source": [
    "def createLineIterator(P1, P2, img):\n",
    "    \"\"\"\n",
    "    Produces and array that consists of the coordinates and intensities of each pixel in a line between two points\n",
    "\n",
    "    Parameters:\n",
    "        -P1: a numpy array that consists of the coordinate of the first point (x,y)\n",
    "        -P2: a numpy array that consists of the coordinate of the second point (x,y)\n",
    "        -img: the image being processed\n",
    "\n",
    "    Returns:\n",
    "        -it: a numpy array that consists of the coordinates and intensities of each pixel in the radii (shape: [numPixels, 3], row = [x,y,intensity])     \n",
    "    \"\"\"\n",
    "    #define local variables for readability\n",
    "    imageH = img.shape[0]\n",
    "    imageW = img.shape[1]\n",
    "    P1X = P1[0]\n",
    "    P1Y = P1[1]\n",
    "    P2X = P2[0]\n",
    "    P2Y = P2[1]\n",
    "\n",
    "    #difference and absolute difference between points\n",
    "    #used to calculate slope and relative location between points\n",
    "    dX = P2X - P1X\n",
    "    dY = P2Y - P1Y\n",
    "    dXa = np.abs(dX)\n",
    "    dYa = np.abs(dY)\n",
    "\n",
    "    #predefine numpy array for output based on distance between points\n",
    "    itbuffer = np.empty(shape=(np.maximum(dYa,dXa),3),dtype=np.float32)\n",
    "    itbuffer.fill(np.nan)\n",
    "\n",
    "    #Obtain coordinates along the line using a form of Bresenham's algorithm\n",
    "    negY = P1Y > P2Y\n",
    "    negX = P1X > P2X\n",
    "    if P1X == P2X: #vertical line segment\n",
    "        itbuffer[:,0] = P1X\n",
    "        if negY:\n",
    "            itbuffer[:,1] = np.arange(P1Y - 1,P1Y - dYa - 1,-1)\n",
    "        else:\n",
    "            itbuffer[:,1] = np.arange(P1Y+1,P1Y+dYa+1)              \n",
    "    elif P1Y == P2Y: #horizontal line segment\n",
    "        itbuffer[:,1] = P1Y\n",
    "        if negX:\n",
    "            itbuffer[:,0] = np.arange(P1X-1,P1X-dXa-1,-1)\n",
    "        else:\n",
    "            itbuffer[:,0] = np.arange(P1X+1,P1X+dXa+1)\n",
    "    else: #diagonal line segment\n",
    "        steepSlope = dYa > dXa\n",
    "        if steepSlope:\n",
    "            slope = dX.astype(np.float32)/dY.astype(np.float32)\n",
    "            if negY:\n",
    "                itbuffer[:,1] = np.arange(P1Y-1,P1Y-dYa-1,-1)\n",
    "            else:\n",
    "                itbuffer[:,1] = np.arange(P1Y+1,P1Y+dYa+1)\n",
    "            itbuffer[:,0] = (slope*(itbuffer[:,1]-P1Y)).astype(np.int) + P1X\n",
    "        else:\n",
    "            slope = dY.astype(np.float32)/dX.astype(np.float32)\n",
    "            if negX:\n",
    "                itbuffer[:,0] = np.arange(P1X-1,P1X-dXa-1,-1)\n",
    "            else:\n",
    "                itbuffer[:,0] = np.arange(P1X+1,P1X+dXa+1)\n",
    "            itbuffer[:,1] = (slope*(itbuffer[:,0]-P1X)).astype(np.int) + P1Y\n",
    "\n",
    "    #Remove points outside of image\n",
    "    colX = itbuffer[:,0]\n",
    "    colY = itbuffer[:,1]\n",
    "    itbuffer = itbuffer[(colX >= 0) & (colY >=0) & (colX<imageW) & (colY<imageH)]\n",
    "\n",
    "    #Get intensities from img ndarray\n",
    "    itbuffer[:,2] = img[itbuffer[:,1].astype(np.uint),itbuffer[:,0].astype(np.uint)]\n",
    "\n",
    "    return itbuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gN7svmg_SJov"
   },
   "outputs": [],
   "source": [
    "def gradx(img):\n",
    "    img = img.astype('int')\n",
    "    rows, cols = img.shape\n",
    "    # Use hstack to add back in the columns that were dropped as zeros\n",
    "    return np.hstack( (np.zeros((rows, 1)), (img[:, 2:] - img[:, :-2])/2.0, np.zeros((rows, 1))) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ssVQM7WLSK3-"
   },
   "outputs": [],
   "source": [
    "def grady(img):\n",
    "    img = img.astype('int')\n",
    "    rows, cols = img.shape\n",
    "    # Use vstack to add back the rows that were dropped as zeros\n",
    "    return np.vstack( (np.zeros((1, cols)), (img[2:, :] - img[:-2, :])/2.0, np.zeros((1, cols))) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0dPlG9v2SXkI"
   },
   "outputs": [],
   "source": [
    "#Performs fast radial symmetry transform\n",
    "#img: input image, grayscale\n",
    "#radii: integer value for radius size in pixels (n in the original paper); also used to size gaussian kernel\n",
    "#alpha: Strictness of symmetry transform (higher=more strict; 2 is good place to start)\n",
    "#beta: gradient threshold parameter, float in [0,1]\n",
    "#stdFactor: Standard deviation factor for gaussian kernel\n",
    "#mode: BRIGHT, DARK, or BOTH\n",
    "def frst(img, radii, alpha, beta, stdFactor, mode='BOTH'):\n",
    "    mode = mode.upper()\n",
    "    assert mode in ['BRIGHT', 'DARK', 'BOTH']\n",
    "    dark = (mode == 'DARK' or mode == 'BOTH')\n",
    "    bright = (mode == 'BRIGHT' or mode == 'BOTH')\n",
    "\n",
    "    workingDims = tuple((e + 2*radii) for e in img.shape)\n",
    "\n",
    "    #M and O working matrices\n",
    "    O_n = np.zeros(workingDims, np.int16)\n",
    "    M_n = np.zeros(workingDims, np.int16)\n",
    "\n",
    "    #Calculate gradients\n",
    "    gx = gradx(img)\n",
    "    gy = grady(img)\n",
    "\n",
    "    #Find gradient vector magnitude\n",
    "    gnorms = np.sqrt( np.add( np.multiply(gx, gx) , np.multiply(gy, gy) ) )\n",
    "\n",
    "    #Use beta to set threshold - speeds up transform significantly\n",
    "    gthresh = np.amax(gnorms)*beta\n",
    "\n",
    "    #Find x/y distance to affected pixels\n",
    "    gpx = np.multiply(np.divide(gx, gnorms, out=np.zeros(gx.shape), where=gnorms!=0), radii).round().astype(int);\n",
    "    gpy = np.multiply(np.divide(gy, gnorms, out=np.zeros(gy.shape), where=gnorms!=0), radii).round().astype(int);\n",
    "\n",
    "    #Iterate over all pixels (w/ gradient above threshold)\n",
    "    for coords, gnorm in np.ndenumerate(gnorms):\n",
    "        if gnorm > gthresh:\n",
    "            i, j = coords\n",
    "            #Positively affected pixel\n",
    "            if bright:\n",
    "                ppve = (i+gpy[i,j]+radii, j+gpx[i,j]+radii)\n",
    "                O_n[ppve] += 1\n",
    "                M_n[ppve] += gnorm\n",
    "            #Negatively affected pixel\n",
    "            if dark:\n",
    "                pnve = (i-gpy[i,j]+radii, j-gpx[i,j]+radii)\n",
    "                O_n[pnve] -= 1\n",
    "                M_n[pnve] -= gnorm\n",
    "\n",
    "    \n",
    "\n",
    "    #Abs and normalize O matrix\n",
    "    O_n = np.abs(O_n)\n",
    "    O_n = O_n / float(np.amax(O_n))\n",
    "\n",
    "    #Normalize M matrix\n",
    "    M_max = float(np.amax(np.abs(M_n)))\n",
    "    M_n = M_n / M_max\n",
    "\n",
    "    #Elementwise multiplication\n",
    "    F_n = np.multiply(np.power(O_n, alpha), M_n)\n",
    "\n",
    "    #Gaussian blur\n",
    "    kSize = int( np.ceil( radii / 2 ) )\n",
    "    kSize = kSize + 1 if kSize % 2 == 0 else kSize\n",
    "\n",
    "    S = cv2.GaussianBlur(F_n, (kSize, kSize), int( radii * stdFactor ))\n",
    "    \n",
    "    return S[radii:-radii,radii:-radii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "epeAKWwQ9W5V"
   },
   "outputs": [],
   "source": [
    "def rough_corneal_remove(gray_frame, replace_val):\n",
    "    # roughly removing corneal reflection\n",
    "    blur_frame = cv2.blur(gray_frame, (5, 5))\n",
    "    ret, thresh_frame = cv2.threshold(blur_frame, replace_val, 255, cv2.THRESH_TRUNC)\n",
    "\n",
    "    '''\n",
    "    for (x, y), value in np.ndenumerate(thresh_frame):\n",
    "        if value > 0:\n",
    "            gray_frame[x, y] = replace_val\n",
    "    '''\n",
    "    \n",
    "    return thresh_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RSzNRhVDw-xZ"
   },
   "outputs": [],
   "source": [
    "def estimate(frame, radius_lst):\n",
    "    # convert frame to grayscale\n",
    "    if len(frame.shape) != 2:\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray_frame = frame\n",
    "\n",
    "    gray_frame = rough_corneal_remove(gray_frame, np.mean(gray_frame))\n",
    "\n",
    "    #frst\n",
    "    frst_sum = np.zeros(gray_frame.shape)\n",
    "    for i in radius_lst:\n",
    "        result = frst(gray_frame, i, 2, 0.2, 0, mode='DARK')\n",
    "        frst_sum = np.add(frst_sum, result)\n",
    "\n",
    "    # argmin finds the min index as if frst_sum is flattened,\n",
    "    # so we have to reverse that using unravel_index\n",
    "    eye_estimate = np.unravel_index(frst_sum.argmin(), frst_sum.shape)[::-1]\n",
    "    \n",
    "    return eye_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0nX4onh6TT57"
   },
   "outputs": [],
   "source": [
    "def starburst(frame, eye):\n",
    "    PIVOT_ANGLE = 15\n",
    "    LINE_LENGTH = 30\n",
    "    DETECTION_THRESHOLD = 4\n",
    "    CORNEAL_REFLECTION_SEARCH_SIZE = 5\n",
    "\n",
    "    # convert frame to grayscale\n",
    "    if len(frame.shape) != 2:\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray_frame = frame\n",
    "\n",
    "    gray_frame = cv2.blur(gray_frame, (5, 5))\n",
    "\n",
    "    test_frame = frame.copy()\n",
    "\n",
    "    feature_points = []\n",
    "    distances = []\n",
    "\n",
    "    for degree in range(0, 360, PIVOT_ANGLE):\n",
    "\n",
    "        radian = degree * math.pi / 180\n",
    "        edge = (int(eye[0] + LINE_LENGTH * math.cos(radian)), \n",
    "                int(eye[1] + LINE_LENGTH * math.sin(radian)))\n",
    "        \n",
    "        line_points = [tupl for tupl in createLineIterator(eye, edge, gray_frame)]\n",
    "        derivative = []\n",
    "\n",
    "        prev_intensity = None\n",
    "        for tupl in line_points:\n",
    "            if prev_intensity is not None:\n",
    "                derivative.append(tupl[2] - prev_intensity)            \n",
    "            prev_intensity = tupl[2]\n",
    "        \n",
    "        for i in range(len(derivative)):\n",
    "            if derivative[i] > DETECTION_THRESHOLD:\n",
    "                corneal_reflection = False\n",
    "                peak_idx = i\n",
    "                for j in range(i + 1, len(derivative)):\n",
    "                    # detecting maximum slope\n",
    "                    if derivative[j] > derivative[peak_idx]:\n",
    "                        peak_idx = j\n",
    "                    # detecting corneal reflection\n",
    "                    elif derivative[j] < -1 * DETECTION_THRESHOLD:\n",
    "                        corneal_reflection = True\n",
    "                    # stop if too long distance\n",
    "                    elif j - peak_idx > CORNEAL_REFLECTION_SEARCH_SIZE:\n",
    "                        break\n",
    "\n",
    "                if not corneal_reflection:\n",
    "                    feature_points.append(line_points[peak_idx][:-1])\n",
    "\n",
    "                break\n",
    "        \n",
    "\n",
    "    return np.array(feature_points)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "i53Kx0k4JKxf"
   },
   "outputs": [],
   "source": [
    "class StarburstProcess(Process):\n",
    "    def __init__(self, input_queue, output_queue, **kwargs):\n",
    "        Process.__init__(self, **kwargs)\n",
    "        self.input_queue = input_queue\n",
    "        self.output_queue = output_queue\n",
    "\n",
    "    def run(self):\n",
    "        LINE_LENGTH = 30\n",
    "        DETECTION_THRESHOLD = 5\n",
    "        CORNEAL_REFLECTION_SEARCH_SIZE = 10\n",
    "\n",
    "        while True:\n",
    "            #input: (angle in degrees, eye, image)\n",
    "            input = self.input_queue.get(block=True)\n",
    "            degree = input[0]\n",
    "            eye = input[1]\n",
    "            gray_frame = input[2]\n",
    "\n",
    "            radian = degree * math.pi / 180\n",
    "            edge = (int(eye[0] + LINE_LENGTH * math.cos(radian)), \n",
    "                    int(eye[1] + LINE_LENGTH * math.sin(radian)))\n",
    "            \n",
    "            line_points = [tupl for tupl in createLineIterator(eye, edge, gray_frame)]\n",
    "            derivative = []\n",
    "\n",
    "            prev_intensity = None\n",
    "            for tupl in line_points:\n",
    "                if prev_intensity is not None:\n",
    "                    derivative.append(tupl[2] - prev_intensity)            \n",
    "                prev_intensity = tupl[2]\n",
    "            \n",
    "            for i in range(len(derivative)):\n",
    "                if i == len(derivative) - 1:\n",
    "                    self.output_queue.put(((0, 0), True)) # no threshold found\n",
    "                if derivative[i] > DETECTION_THRESHOLD:\n",
    "                    corneal_reflection = False\n",
    "                    peak_idx = i\n",
    "                    for j in range(i + 1, len(derivative)):\n",
    "                        # detecting maximum slope\n",
    "                        if derivative[j] > derivative[peak_idx]:\n",
    "                            peak_idx = j\n",
    "                        # detecting corneal reflection\n",
    "                        elif derivative[j] < -1 * DETECTION_THRESHOLD:\n",
    "                            corneal_reflection = True\n",
    "                        # stop if too long distance\n",
    "                        elif j - peak_idx > CORNEAL_REFLECTION_SEARCH_SIZE:\n",
    "                            break\n",
    "\n",
    "                    self.output_queue.put((line_points[peak_idx][:-1], corneal_reflection))\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "8r7QXS7KPPoh"
   },
   "outputs": [],
   "source": [
    "def non_realtime_scheduler(video_filepath, process_count):\n",
    "    Y_MIN = 80\n",
    "    Y_MAX = 175\n",
    "    X_MIN = 100\n",
    "    X_MAX = 200\n",
    "    PIVOT_ANGLE = 15\n",
    "    STARBURST_TO_FRST_RATIO = 5\n",
    "    EYE_SIZE_RANGE = [10, 12, 14]\n",
    "\n",
    "    # create processes\n",
    "    output_queue = Queue()\n",
    "    processes = []\n",
    "    input_queues = []\n",
    "    for i in range(process_count):\n",
    "        input_queues.append(Queue())\n",
    "        processes.append(StarburstProcess(input_queues[i], output_queue))\n",
    "        processes[i].start()\n",
    "\n",
    "    vidcap = cv2.VideoCapture(file_path)\n",
    "    ret, frame = vidcap.read() # first frame is blank\n",
    "    ret, frame = vidcap.read()\n",
    "    frame = frame[Y_MIN:Y_MAX, X_MIN:X_MAX] #crop\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #convert to grayscale\n",
    "    gray_frame = cv2.blur(gray_frame, (5, 5))\n",
    "\n",
    "    progress_bar = tqdm(total=int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "\n",
    "    while ret:\n",
    "\n",
    "        eye = estimate(gray_frame, EYE_SIZE_RANGE)\n",
    "\n",
    "        for i in range(STARBURST_TO_FRST_RATIO):\n",
    "            process_counter = 0\n",
    "            for degree in range(0, 360, PIVOT_ANGLE):            \n",
    "                input_queues[process_counter].put((degree, eye, gray_frame))\n",
    "                \n",
    "                if process_counter == process_count - 1:\n",
    "                    process_counter = 0\n",
    "                else:\n",
    "                    process_counter += 1\n",
    "\n",
    "            feature_points = []\n",
    "            for i in range(int(360 / PIVOT_ANGLE)):\n",
    "                result_tuple = output_queue.get(block=True) #(point, corneal_reflection_bool)\n",
    "                \n",
    "                if not result_tuple[1]:\n",
    "                    feature_points.append(result_tuple[0])\n",
    "\n",
    "            contour = np.array(feature_points)\n",
    "            if len(contour) >= 5:\n",
    "                fitted_ellipse = cv2.fitEllipse(contour)\n",
    "            \n",
    "            progress_bar.update(n=1)\n",
    "            ret, frame = vidcap.read()\n",
    "            if ret:\n",
    "                frame = frame[Y_MIN:Y_MAX, X_MIN:X_MAX] #crop\n",
    "                gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #convert to grayscale\n",
    "                gray_frame = cv2.blur(gray_frame, (5, 5))\n",
    "            else:\n",
    "                print(ret)\n",
    "                return\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wSdizC2xZq3W",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#file_path = \"fixedSFblink.avi\"\n",
    "#non_realtime_scheduler(file_path, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfile_path = \"exampletracking.avi\"\\nvidcap = cv2.VideoCapture(file_path)\\n\\nret, frame = vidcap.read()\\nret, frame = vidcap.read()\\ncrop_frame = frame[80:175, 100:200]\\n\\nfourcc = cv2.VideoWriter_fourcc(*\\'XVID\\')\\nvidwrite = cv2.VideoWriter(\\'exampletracking_tracked.avi\\', fourcc, 100, (frame.shape[1], frame.shape[0]))\\n\\nprogress_bar = tqdm(total=int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT)))\\n\\nwhile ret:\\n    eye = estimate(crop_frame, [12, 14])\\n\\n    for i in range(5):\\n        contour = starburst(frame, (eye[0] + 100, eye[1] + 80))\\n        if len(contour) >= 5:\\n            fitted_ellipse = cv2.fitEllipse(contour)\\n\\n        # drawing\\n        for point in contour:\\n            cv2.circle(frame, tuple(point), 1, (0, 255, 0))\\n        cv2.circle(frame, tuple((eye[0]+100, eye[1]+80)), 5, (0, 0, 255))\\n        cv2.ellipse(frame, fitted_ellipse, (255, 255, 255), 1)\\n        vidwrite.write(frame)\\n\\n        ret, frame = vidcap.read()\\n        if not ret:\\n            break\\n        crop_frame = frame[80:175, 100:200]\\n        progress_bar.update(n=1)\\n\\nvidcap.release()\\nvidwrite.release()\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "file_path = \"exampletracking.avi\"\n",
    "vidcap = cv2.VideoCapture(file_path)\n",
    "\n",
    "ret, frame = vidcap.read()\n",
    "ret, frame = vidcap.read()\n",
    "crop_frame = frame[80:175, 100:200]\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "vidwrite = cv2.VideoWriter('exampletracking_tracked.avi', fourcc, 100, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "progress_bar = tqdm(total=int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "\n",
    "while ret:\n",
    "    eye = estimate(crop_frame, [12, 14])\n",
    "\n",
    "    for i in range(5):\n",
    "        contour = starburst(frame, (eye[0] + 100, eye[1] + 80))\n",
    "        if len(contour) >= 5:\n",
    "            fitted_ellipse = cv2.fitEllipse(contour)\n",
    "\n",
    "        # drawing\n",
    "        for point in contour:\n",
    "            cv2.circle(frame, tuple(point), 1, (0, 255, 0))\n",
    "        cv2.circle(frame, tuple((eye[0]+100, eye[1]+80)), 5, (0, 0, 255))\n",
    "        cv2.ellipse(frame, fitted_ellipse, (255, 255, 255), 1)\n",
    "        vidwrite.write(frame)\n",
    "\n",
    "        ret, frame = vidcap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        crop_frame = frame[80:175, 100:200]\n",
    "        progress_bar.update(n=1)\n",
    "\n",
    "vidcap.release()\n",
    "vidwrite.release()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM+xL/fltkmmZLRKGcjqyz/",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "eye_test.py",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
