{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "eye_test.py",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+xL/fltkmmZLRKGcjqyz/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JimmyLiu8351/liulabtracking/blob/main/eye_test_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzLp7ssS88CL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a398dd0-43d7-4e76-d82e-5c6defdcea05"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import math\n",
        "import cProfile\n",
        "import pstats\n",
        "import time\n",
        "\n",
        "from tqdm import tqdm\n",
        "from multiprocessing import Pool, Process, Queue, Manager"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9X5jjkTrOGX5"
      },
      "source": [
        "def createLineIterator(P1, P2, img):\r\n",
        "    \"\"\"\r\n",
        "    Produces and array that consists of the coordinates and intensities of each pixel in a line between two points\r\n",
        "\r\n",
        "    Parameters:\r\n",
        "        -P1: a numpy array that consists of the coordinate of the first point (x,y)\r\n",
        "        -P2: a numpy array that consists of the coordinate of the second point (x,y)\r\n",
        "        -img: the image being processed\r\n",
        "\r\n",
        "    Returns:\r\n",
        "        -it: a numpy array that consists of the coordinates and intensities of each pixel in the radii (shape: [numPixels, 3], row = [x,y,intensity])     \r\n",
        "    \"\"\"\r\n",
        "    #define local variables for readability\r\n",
        "    imageH = img.shape[0]\r\n",
        "    imageW = img.shape[1]\r\n",
        "    P1X = P1[0]\r\n",
        "    P1Y = P1[1]\r\n",
        "    P2X = P2[0]\r\n",
        "    P2Y = P2[1]\r\n",
        "\r\n",
        "    #difference and absolute difference between points\r\n",
        "    #used to calculate slope and relative location between points\r\n",
        "    dX = P2X - P1X\r\n",
        "    dY = P2Y - P1Y\r\n",
        "    dXa = np.abs(dX)\r\n",
        "    dYa = np.abs(dY)\r\n",
        "\r\n",
        "    #predefine numpy array for output based on distance between points\r\n",
        "    itbuffer = np.empty(shape=(np.maximum(dYa,dXa),3),dtype=np.float32)\r\n",
        "    itbuffer.fill(np.nan)\r\n",
        "\r\n",
        "    #Obtain coordinates along the line using a form of Bresenham's algorithm\r\n",
        "    negY = P1Y > P2Y\r\n",
        "    negX = P1X > P2X\r\n",
        "    if P1X == P2X: #vertical line segment\r\n",
        "        itbuffer[:,0] = P1X\r\n",
        "        if negY:\r\n",
        "            itbuffer[:,1] = np.arange(P1Y - 1,P1Y - dYa - 1,-1)\r\n",
        "        else:\r\n",
        "            itbuffer[:,1] = np.arange(P1Y+1,P1Y+dYa+1)              \r\n",
        "    elif P1Y == P2Y: #horizontal line segment\r\n",
        "        itbuffer[:,1] = P1Y\r\n",
        "        if negX:\r\n",
        "            itbuffer[:,0] = np.arange(P1X-1,P1X-dXa-1,-1)\r\n",
        "        else:\r\n",
        "            itbuffer[:,0] = np.arange(P1X+1,P1X+dXa+1)\r\n",
        "    else: #diagonal line segment\r\n",
        "        steepSlope = dYa > dXa\r\n",
        "        if steepSlope:\r\n",
        "            slope = dX.astype(np.float32)/dY.astype(np.float32)\r\n",
        "            if negY:\r\n",
        "                itbuffer[:,1] = np.arange(P1Y-1,P1Y-dYa-1,-1)\r\n",
        "            else:\r\n",
        "                itbuffer[:,1] = np.arange(P1Y+1,P1Y+dYa+1)\r\n",
        "            itbuffer[:,0] = (slope*(itbuffer[:,1]-P1Y)).astype(np.int) + P1X\r\n",
        "        else:\r\n",
        "            slope = dY.astype(np.float32)/dX.astype(np.float32)\r\n",
        "            if negX:\r\n",
        "                itbuffer[:,0] = np.arange(P1X-1,P1X-dXa-1,-1)\r\n",
        "            else:\r\n",
        "                itbuffer[:,0] = np.arange(P1X+1,P1X+dXa+1)\r\n",
        "            itbuffer[:,1] = (slope*(itbuffer[:,0]-P1X)).astype(np.int) + P1Y\r\n",
        "\r\n",
        "    #Remove points outside of image\r\n",
        "    colX = itbuffer[:,0]\r\n",
        "    colY = itbuffer[:,1]\r\n",
        "    itbuffer = itbuffer[(colX >= 0) & (colY >=0) & (colX<imageW) & (colY<imageH)]\r\n",
        "\r\n",
        "    #Get intensities from img ndarray\r\n",
        "    itbuffer[:,2] = img[itbuffer[:,1].astype(np.uint),itbuffer[:,0].astype(np.uint)]\r\n",
        "\r\n",
        "    return itbuffer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN7svmg_SJov"
      },
      "source": [
        "def gradx(img):\n",
        "    img = img.astype('int')\n",
        "    rows, cols = img.shape\n",
        "    # Use hstack to add back in the columns that were dropped as zeros\n",
        "    return np.hstack( (np.zeros((rows, 1)), (img[:, 2:] - img[:, :-2])/2.0, np.zeros((rows, 1))) )"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssVQM7WLSK3-"
      },
      "source": [
        "def grady(img):\n",
        "    img = img.astype('int')\n",
        "    rows, cols = img.shape\n",
        "    # Use vstack to add back the rows that were dropped as zeros\n",
        "    return np.vstack( (np.zeros((1, cols)), (img[2:, :] - img[:-2, :])/2.0, np.zeros((1, cols))) )"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dPlG9v2SXkI"
      },
      "source": [
        "#Performs fast radial symmetry transform\n",
        "#img: input image, grayscale\n",
        "#radii: integer value for radius size in pixels (n in the original paper); also used to size gaussian kernel\n",
        "#alpha: Strictness of symmetry transform (higher=more strict; 2 is good place to start)\n",
        "#beta: gradient threshold parameter, float in [0,1]\n",
        "#stdFactor: Standard deviation factor for gaussian kernel\n",
        "#mode: BRIGHT, DARK, or BOTH\n",
        "def frst(img, radii, alpha, beta, stdFactor, mode='BOTH'):\n",
        "    mode = mode.upper()\n",
        "    assert mode in ['BRIGHT', 'DARK', 'BOTH']\n",
        "    dark = (mode == 'DARK' or mode == 'BOTH')\n",
        "    bright = (mode == 'BRIGHT' or mode == 'BOTH')\n",
        "\n",
        "    workingDims = tuple((e + 2*radii) for e in img.shape)\n",
        "\n",
        "    #M and O working matrices\n",
        "    O_n = np.zeros(workingDims, np.int16)\n",
        "    M_n = np.zeros(workingDims, np.int16)\n",
        "\n",
        "    #Calculate gradients\n",
        "    gx = gradx(img)\n",
        "    gy = grady(img)\n",
        "\n",
        "    #Find gradient vector magnitude\n",
        "    gnorms = np.sqrt( np.add( np.multiply(gx, gx) , np.multiply(gy, gy) ) )\n",
        "\n",
        "    #Use beta to set threshold - speeds up transform significantly\n",
        "    gthresh = np.amax(gnorms)*beta\n",
        "\n",
        "    #Find x/y distance to affected pixels\n",
        "    gpx = np.multiply(np.divide(gx, gnorms, out=np.zeros(gx.shape), where=gnorms!=0), radii).round().astype(int);\n",
        "    gpy = np.multiply(np.divide(gy, gnorms, out=np.zeros(gy.shape), where=gnorms!=0), radii).round().astype(int);\n",
        "\n",
        "    #Iterate over all pixels (w/ gradient above threshold)\n",
        "    for coords, gnorm in np.ndenumerate(gnorms):\n",
        "        if gnorm > gthresh:\n",
        "            i, j = coords\n",
        "            #Positively affected pixel\n",
        "            if bright:\n",
        "                ppve = (i+gpy[i,j]+radii, j+gpx[i,j]+radii)\n",
        "                O_n[ppve] += 1\n",
        "                M_n[ppve] += gnorm\n",
        "            #Negatively affected pixel\n",
        "            if dark:\n",
        "                pnve = (i-gpy[i,j]+radii, j-gpx[i,j]+radii)\n",
        "                O_n[pnve] -= 1\n",
        "                M_n[pnve] -= gnorm\n",
        "\n",
        "    \n",
        "\n",
        "    #Abs and normalize O matrix\n",
        "    O_n = np.abs(O_n)\n",
        "    O_n = O_n / float(np.amax(O_n))\n",
        "\n",
        "    #Normalize M matrix\n",
        "    M_max = float(np.amax(np.abs(M_n)))\n",
        "    M_n = M_n / M_max\n",
        "\n",
        "    #Elementwise multiplication\n",
        "    F_n = np.multiply(np.power(O_n, alpha), M_n)\n",
        "\n",
        "    #Gaussian blur\n",
        "    kSize = int( np.ceil( radii / 2 ) )\n",
        "    kSize = kSize + 1 if kSize % 2 == 0 else kSize\n",
        "\n",
        "    S = cv2.GaussianBlur(F_n, (kSize, kSize), int( radii * stdFactor ))\n",
        "    \n",
        "    return S[radii:-radii,radii:-radii]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epeAKWwQ9W5V"
      },
      "source": [
        "def rough_corneal_remove(gray_frame, replace_val):\n",
        "    # roughly removing corneal reflection\n",
        "    blur_frame = cv2.blur(gray_frame, (5, 5))\n",
        "    ret, thresh_frame = cv2.threshold(blur_frame, replace_val, 255, cv2.THRESH_TRUNC)\n",
        "\n",
        "    '''\n",
        "    for (x, y), value in np.ndenumerate(thresh_frame):\n",
        "        if value > 0:\n",
        "            gray_frame[x, y] = replace_val\n",
        "    '''\n",
        "    \n",
        "    return thresh_frame"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSzNRhVDw-xZ"
      },
      "source": [
        "def estimate(frame, radius_lst):\n",
        "    # convert frame to grayscale\n",
        "    if len(frame.shape) != 2:\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray_frame = frame\n",
        "\n",
        "    gray_frame = rough_corneal_remove(gray_frame, np.mean(gray_frame))\n",
        "\n",
        "    #frst\n",
        "    frst_sum = np.zeros(gray_frame.shape)\n",
        "    for i in radius_lst:\n",
        "        result = frst(gray_frame, i, 2, 0.2, 0, mode='DARK')\n",
        "        frst_sum = np.add(frst_sum, result)\n",
        "\n",
        "    # argmin finds the min index as if frst_sum is flattened,\n",
        "    # so we have to reverse that using unravel_index\n",
        "    eye_estimate = np.unravel_index(frst_sum.argmin(), frst_sum.shape)[::-1]\n",
        "    \n",
        "    return eye_estimate"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nX4onh6TT57"
      },
      "source": [
        "def starburst(frame, eye):\n",
        "    PIVOT_ANGLE = 15\n",
        "    LINE_LENGTH = 30\n",
        "    DETECTION_THRESHOLD = 4\n",
        "    CORNEAL_REFLECTION_SEARCH_SIZE = 5\n",
        "\n",
        "    # convert frame to grayscale\n",
        "    if len(frame.shape) != 2:\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "        gray_frame = frame\n",
        "\n",
        "    gray_frame = cv2.blur(gray_frame, (5, 5))\n",
        "\n",
        "    test_frame = frame.copy()\n",
        "\n",
        "    feature_points = []\n",
        "    distances = []\n",
        "\n",
        "    for degree in range(0, 360, PIVOT_ANGLE):\n",
        "\n",
        "        radian = degree * math.pi / 180\n",
        "        edge = (int(eye[0] + LINE_LENGTH * math.cos(radian)), \n",
        "                int(eye[1] + LINE_LENGTH * math.sin(radian)))\n",
        "        \n",
        "        line_points = [tupl for tupl in createLineIterator(eye, edge, gray_frame)]\n",
        "        derivative = []\n",
        "\n",
        "        prev_intensity = None\n",
        "        for tupl in line_points:\n",
        "            if prev_intensity is not None:\n",
        "                derivative.append(tupl[2] - prev_intensity)            \n",
        "            prev_intensity = tupl[2]\n",
        "        \n",
        "        for i in range(len(derivative)):\n",
        "            if derivative[i] > DETECTION_THRESHOLD:\n",
        "                corneal_reflection = False\n",
        "                peak_idx = i\n",
        "                for j in range(i + 1, len(derivative)):\n",
        "                    # detecting maximum slope\n",
        "                    if derivative[j] > derivative[peak_idx]:\n",
        "                        peak_idx = j\n",
        "                    # detecting corneal reflection\n",
        "                    elif derivative[j] < -1 * DETECTION_THRESHOLD:\n",
        "                        corneal_reflection = True\n",
        "                    # stop if too long distance\n",
        "                    elif j - peak_idx > CORNEAL_REFLECTION_SEARCH_SIZE:\n",
        "                        break\n",
        "\n",
        "                if not corneal_reflection:\n",
        "                    feature_points.append(line_points[peak_idx][:-1])\n",
        "\n",
        "                break\n",
        "        \n",
        "\n",
        "    return np.array(feature_points)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSHlIeLzyLdA"
      },
      "source": [
        "def non_realtime_scheduler(filepath, process_count):\n",
        "    Y_MIN = 80\n",
        "    Y_MAX = 175\n",
        "    X_MIN = 100\n",
        "    X_MAX = 200\n",
        "    STARBURST_TO_FRST_RATIO = 5\n",
        "    EYE_SIZE_RANGE = [10, 12, 14]\n",
        "\n",
        "    vidcap = cv2.VideoCapture(filepath)\n",
        "    ret, frame = vidcap.read() # first frame is blank\n",
        "\n",
        "    progress_bar = tqdm(total=int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "\n",
        "    with Pool(processes=process_count) as pool:\n",
        "        m = Manager()\n",
        "        output_queue = m.Queue()\n",
        "        while ret:\n",
        "            ret, frame = vidcap.read()        \n",
        "            frame = frame[Y_MIN:Y_MAX, X_MIN:X_MAX] #crop\n",
        "            eye = estimate(frame, EYE_SIZE_RANGE)\n",
        "            \n",
        "            frames = []\n",
        "            for i in range(STARBURST_TO_FRST_RATIO):\n",
        "                ret, frame = vidcap.read()\n",
        "                if ret:\n",
        "                    frame = frame[Y_MIN:Y_MAX, X_MIN:X_MAX] #crop\n",
        "                    frames.append((eye, frame, output_queue, i))\n",
        "                else:\n",
        "                    return\n",
        "\n",
        "            pool.map(non_realtime_function, frames)\n",
        "\n",
        "            ellipses = []\n",
        "            for i in range(STARBURST_TO_FRST_RATIO):\n",
        "                ellipse = output_queue.get(block=True)\n",
        "                if ellipse is not None:\n",
        "                    ellipses.append(ellipse)\n",
        "            \n",
        "            ellipses = sorted(ellipses, key=lambda ellipse: ellipse[0])\n",
        "\n",
        "            progress_bar.update(n=process_count)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWYZdh-Y_9Lw"
      },
      "source": [
        "def non_realtime_function(input):\n",
        "    eye = input[0]\n",
        "    frame = input[1]\n",
        "    output_queue = input[2]\n",
        "    idx = input[3]\n",
        "\n",
        "    contour = starburst(frame, eye)\n",
        "    if len(contour) >= 5:\n",
        "        fitted_ellipse = cv2.fitEllipse(contour)\n",
        "        output_queue.put((idx, fitted_ellipse))\n",
        "    else:\n",
        "        output_queue.put(None)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i53Kx0k4JKxf"
      },
      "source": [
        "class StarburstProcess(Process):\r\n",
        "    def __init__(self, input_queue, output_queue, **kwargs):\r\n",
        "        Process.__init__(self, **kwargs)\r\n",
        "        self.input_queue = input_queue\r\n",
        "        self.output_queue = output_queue\r\n",
        "\r\n",
        "    def run(self):\r\n",
        "        LINE_LENGTH = 30\r\n",
        "        DETECTION_THRESHOLD = 5\r\n",
        "        CORNEAL_REFLECTION_SEARCH_SIZE = 10\r\n",
        "\r\n",
        "        while True:\r\n",
        "            #input: (angle in degrees, eye, image)\r\n",
        "            input = self.input_queue.get(block=True)\r\n",
        "            degree = input[0]\r\n",
        "            eye = input[1]\r\n",
        "            gray_frame = input[2]\r\n",
        "\r\n",
        "            radian = degree * math.pi / 180\r\n",
        "            edge = (int(eye[0] + LINE_LENGTH * math.cos(radian)), \r\n",
        "                    int(eye[1] + LINE_LENGTH * math.sin(radian)))\r\n",
        "            \r\n",
        "            line_points = [tupl for tupl in createLineIterator(eye, edge, gray_frame)]\r\n",
        "            derivative = []\r\n",
        "\r\n",
        "            prev_intensity = None\r\n",
        "            for tupl in line_points:\r\n",
        "                if prev_intensity is not None:\r\n",
        "                    derivative.append(tupl[2] - prev_intensity)            \r\n",
        "                prev_intensity = tupl[2]\r\n",
        "            \r\n",
        "            for i in range(len(derivative)):\r\n",
        "                if i == len(derivative) - 1:\r\n",
        "                    self.output_queue.put(((0, 0), True)) # no threshold found\r\n",
        "                if derivative[i] > DETECTION_THRESHOLD:\r\n",
        "                    corneal_reflection = False\r\n",
        "                    peak_idx = i\r\n",
        "                    for j in range(i + 1, len(derivative)):\r\n",
        "                        # detecting maximum slope\r\n",
        "                        if derivative[j] > derivative[peak_idx]:\r\n",
        "                            peak_idx = j\r\n",
        "                        # detecting corneal reflection\r\n",
        "                        elif derivative[j] < -1 * DETECTION_THRESHOLD:\r\n",
        "                            corneal_reflection = True\r\n",
        "                        # stop if too long distance\r\n",
        "                        elif j - peak_idx > CORNEAL_REFLECTION_SEARCH_SIZE:\r\n",
        "                            break\r\n",
        "\r\n",
        "                    self.output_queue.put((line_points[peak_idx][:-1], corneal_reflection))\r\n",
        "                    break\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8r7QXS7KPPoh"
      },
      "source": [
        "def realtime_scheduler(video_filepath, process_count):\n",
        "    Y_MIN = 80\n",
        "    Y_MAX = 175\n",
        "    X_MIN = 100\n",
        "    X_MAX = 200\n",
        "    PIVOT_ANGLE = 15\n",
        "    STARBURST_TO_FRST_RATIO = 5\n",
        "    EYE_SIZE_RANGE = [10, 12, 14]\n",
        "\n",
        "    # create processes\n",
        "    output_queue = Queue()\n",
        "    processes = []\n",
        "    input_queues = []\n",
        "    for i in range(process_count):\n",
        "        input_queues.append(Queue())\n",
        "        processes.append(StarburstProcess(input_queues[i], output_queue))\n",
        "        processes[i].start()\n",
        "\n",
        "    vidcap = cv2.VideoCapture(file_path)\n",
        "    ret, frame = vidcap.read() # first frame is blank\n",
        "    ret, frame = vidcap.read()\n",
        "    frame = frame[Y_MIN:Y_MAX, X_MIN:X_MAX] #crop\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #convert to grayscale\n",
        "    gray_frame = cv2.blur(gray_frame, (5, 5))\n",
        "\n",
        "    progress_bar = tqdm(total=int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "\n",
        "    while ret:\n",
        "\n",
        "        eye = estimate(gray_frame, EYE_SIZE_RANGE)\n",
        "\n",
        "        for i in range(STARBURST_TO_FRST_RATIO):\n",
        "            process_counter = 0\n",
        "            for degree in range(0, 360, PIVOT_ANGLE):            \n",
        "                input_queues[process_counter].put((degree, eye, gray_frame))\n",
        "                \n",
        "                if process_counter == process_count - 1:\n",
        "                    process_counter = 0\n",
        "                else:\n",
        "                    process_counter += 1\n",
        "\n",
        "            feature_points = []\n",
        "            for i in range(int(360 / PIVOT_ANGLE)):\n",
        "                result_tuple = output_queue.get(block=True) #(point, corneal_reflection_bool)\n",
        "                \n",
        "                if not result_tuple[1]:\n",
        "                    feature_points.append(result_tuple[0])\n",
        "\n",
        "            contour = np.array(feature_points)\n",
        "            if len(contour) >= 5:\n",
        "                fitted_ellipse = cv2.fitEllipse(contour)\n",
        "            \n",
        "            progress_bar.update(n=1)\n",
        "            ret, frame = vidcap.read()\n",
        "            if ret:\n",
        "                frame = frame[Y_MIN:Y_MAX, X_MIN:X_MAX] #crop\n",
        "                gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #convert to grayscale\n",
        "                gray_frame = cv2.blur(gray_frame, (5, 5))\n",
        "            else:\n",
        "                print(ret)\n",
        "                return\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSdizC2xZq3W",
        "tags": []
      },
      "source": [
        "#file_path = \"fixedSFblink.avi\"\n",
        "#non_realtime_scheduler(file_path, 16)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfile_path = \"exampletracking.avi\"\\nvidcap = cv2.VideoCapture(file_path)\\n\\nret, frame = vidcap.read()\\nret, frame = vidcap.read()\\ncrop_frame = frame[80:175, 100:200]\\n\\nfourcc = cv2.VideoWriter_fourcc(*\\'XVID\\')\\nvidwrite = cv2.VideoWriter(\\'exampletracking_tracked.avi\\', fourcc, 100, (frame.shape[1], frame.shape[0]))\\n\\nprogress_bar = tqdm(total=int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT)))\\n\\nwhile ret:\\n    eye = estimate(crop_frame, [12, 14])\\n\\n    for i in range(5):\\n        contour = starburst(frame, (eye[0] + 100, eye[1] + 80))\\n        if len(contour) >= 5:\\n            fitted_ellipse = cv2.fitEllipse(contour)\\n\\n        # drawing\\n        for point in contour:\\n            cv2.circle(frame, tuple(point), 1, (0, 255, 0))\\n        cv2.circle(frame, tuple((eye[0]+100, eye[1]+80)), 5, (0, 0, 255))\\n        cv2.ellipse(frame, fitted_ellipse, (255, 255, 255), 1)\\n        vidwrite.write(frame)\\n\\n        ret, frame = vidcap.read()\\n        if not ret:\\n            break\\n        crop_frame = frame[80:175, 100:200]\\n        progress_bar.update(n=1)\\n\\nvidcap.release()\\nvidwrite.release()\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "'''\n",
        "file_path = \"exampletracking.avi\"\n",
        "vidcap = cv2.VideoCapture(file_path)\n",
        "\n",
        "ret, frame = vidcap.read()\n",
        "ret, frame = vidcap.read()\n",
        "crop_frame = frame[80:175, 100:200]\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "vidwrite = cv2.VideoWriter('exampletracking_tracked.avi', fourcc, 100, (frame.shape[1], frame.shape[0]))\n",
        "\n",
        "progress_bar = tqdm(total=int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
        "\n",
        "while ret:\n",
        "    eye = estimate(crop_frame, [12, 14])\n",
        "\n",
        "    for i in range(5):\n",
        "        contour = starburst(frame, (eye[0] + 100, eye[1] + 80))\n",
        "        if len(contour) >= 5:\n",
        "            fitted_ellipse = cv2.fitEllipse(contour)\n",
        "\n",
        "        # drawing\n",
        "        for point in contour:\n",
        "            cv2.circle(frame, tuple(point), 1, (0, 255, 0))\n",
        "        cv2.circle(frame, tuple((eye[0]+100, eye[1]+80)), 5, (0, 0, 255))\n",
        "        cv2.ellipse(frame, fitted_ellipse, (255, 255, 255), 1)\n",
        "        vidwrite.write(frame)\n",
        "\n",
        "        ret, frame = vidcap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        crop_frame = frame[80:175, 100:200]\n",
        "        progress_bar.update(n=1)\n",
        "\n",
        "vidcap.release()\n",
        "vidwrite.release()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def non_realtime_scheduler_upgrade(filepath, output_filepath, process_count):\n",
        "    STARBURST_TO_FRST_RATIO = 5\n",
        "\n",
        "    vidcap = cv2.VideoCapture(filepath)\n",
        "    frame_count = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "    ret, frame = vidcap.read() # first frame is blank\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    vidwrite = cv2.VideoWriter(output_filepath, fourcc, 100, (frame.shape[1], frame.shape[0]))\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    print('Reading and caching frames')\n",
        "\n",
        "    chunked_frames = []\n",
        "    while ret:\n",
        "        frst_chunk = []\n",
        "        for i in range(STARBURST_TO_FRST_RATIO):\n",
        "            ret, frame = vidcap.read()\n",
        "            if ret is not False:\n",
        "                frst_chunk.append(frame)\n",
        "            else:\n",
        "                break\n",
        "        chunked_frames.append(frst_chunk)\n",
        "\n",
        "    print('Processing frames')\n",
        "\n",
        "    with Pool(processes=process_count) as pool:\n",
        "\n",
        "        results = pool.map(non_realtime_function_upgrade, chunked_frames)\n",
        "\n",
        "        for chunk in results:\n",
        "            for frame_info in chunk:\n",
        "                frame = frame_info[0]\n",
        "                eye = frame_info[1]\n",
        "                contour = frame_info[2]\n",
        "                fitted_ellipse = frame_info[3]\n",
        "\n",
        "                # drawing\n",
        "                for point in contour:\n",
        "                    cv2.circle(frame, tuple(point), 1, (0, 255, 0))\n",
        "                cv2.circle(frame, tuple(eye), 5, (0, 0, 255))\n",
        "                if fitted_ellipse is not None:\n",
        "                    cv2.ellipse(frame, fitted_ellipse, (255, 255, 255), 1)\n",
        "                vidwrite.write(frame)\n",
        "\n",
        "    vidcap.release()            \n",
        "    vidwrite.release()\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    print(frame_count / (end - start))\n",
        "    \n",
        "\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def non_realtime_function_upgrade(frames):\n",
        "    Y_MIN = 80\n",
        "    Y_MAX = 175\n",
        "    X_MIN = 100\n",
        "    X_MAX = 200\n",
        "    PIVOT_ANGLE = 15\n",
        "    STARBURST_TO_FRST_RATIO = 5\n",
        "    EYE_SIZE_RANGE = [10, 12, 14]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # crop frame to run frst more efficiently\n",
        "    crop_frame = frames[0][Y_MIN:Y_MAX, X_MIN:X_MAX]\n",
        "    eye = estimate(crop_frame, EYE_SIZE_RANGE)\n",
        "    # shift eye location to be for full picture\n",
        "    eye_adjusted = (eye[0] + X_MIN, eye[1] + Y_MIN)\n",
        "\n",
        "    for frame in frames:\n",
        "        contour = starburst(frame, eye_adjusted)\n",
        "        if len(contour) > 5:\n",
        "            fitted_ellipse = cv2.fitEllipse(contour)\n",
        "            results.append((frame, eye_adjusted, contour, fitted_ellipse))\n",
        "        else:\n",
        "            results.append((frame, eye_adjusted, contour, None))\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading and caching frames\n",
            "Processing frames\n",
            "544.2556189465213\n"
          ]
        }
      ],
      "source": [
        "file_path = \"fixedSFblink.avi\"\n",
        "non_realtime_scheduler_upgrade(file_path, 'upgraded_test_output.avi', 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}